import streamlit as st
import re
import urllib.parse
from docx import Document
import tempfile
import requests
from difflib import SequenceMatcher
import pandas as pd

# ========== API Key ç®¡ç† ==========
def get_scopus_key():
    try:
        return st.secrets["scopus_api_key"]
    except Exception:
        try:
            with open("scopus_key.txt", "r") as f:
                return f.read().strip()
        except FileNotFoundError:
            st.error("âŒ æ‰¾ä¸åˆ° Scopus API é‡‘é‘°ï¼Œè«‹ç¢ºèªå·²è¨­å®š secrets æˆ–æä¾› scopus_key.txt")
            st.stop()

SCOPUS_API_KEY = get_scopus_key()

# ========== æ¸…æ´—æ¨™é¡Œ ==========
def clean_title(text):
    # å»é™¤æ¨™é»ã€ç©ºç™½ï¼Œä¸¦è½‰ç‚ºå°å¯«
    return re.sub(r'\W+', '', text).lower()

# ========== ç›¸ä¼¼åº¦åˆ¤æ–· ==========
def is_similar(a, b, threshold=0.9):
    return SequenceMatcher(None, a, b).ratio() >= threshold

# ========== Crossref æŸ¥è©¢ ==========
def search_crossref_by_title(title):
    crossref_email = st.secrets.get("crossref_email", "your_email@example.com")  # â† ä½¿ç”¨è€…è¨˜å¾—è‡ªè¡Œä¿®æ”¹
    url = "https://api.crossref.org/works"
    params = {
        "query.title": title,
        "rows": 5,
        "mailto": crossref_email
    }

    response = requests.get(url, params=params)
    if response.status_code != 200:
        return (None, None)

    items = response.json().get("message", {}).get("items", [])
    cleaned_input = clean_title(title)

    for item in items:
        cr_title = item.get("title", [""])[0]
        cr_url = item.get("URL")
        cleaned_cr_title = clean_title(cr_title)

        if cleaned_input == cleaned_cr_title:
            return ("exact", cr_url)
        elif is_similar(cleaned_input, cleaned_cr_title, threshold=0.9):
            return ("similar", cr_url)

    return (None, None)

# ========== Scopus æŸ¥è©¢ ==========
def search_scopus_by_title(title):
    base_url = "https://api.elsevier.com/content/search/scopus"
    headers = {
        "Accept": "application/json",
        "X-ELS-APIKey": SCOPUS_API_KEY
    }
    params = {
        "query": f'TITLE("{title}")',
        "count": 5
    }
    response = requests.get(base_url, headers=headers, params=params)
    if response.status_code == 200:
        data = response.json()
        entries = data.get('search-results', {}).get('entry', [])
        for entry in entries:
            doc_title = entry.get('dc:title', '')
            if doc_title.strip().lower() == title.strip().lower():
                return entry.get('prism:url', 'https://www.scopus.com')
    return None

# ========== Word è™•ç† ==========
def extract_paragraphs_from_docx(file):
    doc = Document(file)
    return [para.text.strip() for para in doc.paragraphs if para.text.strip()]

def extract_reference_section(paragraphs, start_keyword):
    start_index = -1
    for i, p in enumerate(paragraphs):
        if start_keyword.lower() in p.lower():
            start_index = i + 1
            break
    return paragraphs[start_index:] if start_index != -1 else []

# ========== æ“·å–æ¨™é¡Œ ==========
def extract_title(ref_text, style):
    if style == "APA":
        match = re.search(r'\(\d{4}\)\.\s(.+?)(\.|\n|$)', ref_text)
        if match:
            return match.group(1).strip()
    elif style == "IEEE":
        match = re.search(r'"(.+?)"', ref_text)
        if match:
            return match.group(1).strip()
    return None

# ========== Streamlit UI ==========
st.set_page_config(page_title="Reference Checker", layout="centered")
st.title("ğŸ“š Reference Checker")
st.write("ä¸Šå‚³ Word æª” (.docx)ï¼Œè‡ªå‹•æŸ¥è©¢ Scopus â†’ Crossrefï¼Œåˆ†é¡ç‚ºå››é¡")

uploaded_file = st.file_uploader("è«‹ä¸Šå‚³ Word æª”æ¡ˆï¼ˆ.docxï¼‰", type=["docx"])
style = st.selectbox("è«‹é¸æ“‡åƒè€ƒæ–‡ç»æ ¼å¼", ["APA", "IEEE"])
start_keyword = st.selectbox("è«‹é¸æ“‡åƒè€ƒæ–‡ç»èµ·å§‹æ¨™é¡Œ", ["åƒè€ƒæ–‡ç»", "References", "Reference"])

# ========== ä¸Šå‚³ä¸¦è™•ç† ==========
if uploaded_file:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".docx") as tmp:
        tmp.write(uploaded_file.read())
        tmp_path = tmp.name

    paragraphs = extract_paragraphs_from_docx(tmp_path)
    references = extract_reference_section(paragraphs, start_keyword)

    if not references:
        st.warning("âš ï¸ æ‰¾ä¸åˆ°åƒè€ƒæ–‡ç»æ®µè½ï¼Œè«‹ç¢ºèªé—œéµå­—æ˜¯å¦æ­£ç¢ºã€‚")
    else:
        titles = []
        for ref in references:
            title = extract_title(ref, style)
            if title:
                titles.append(title)

        # âœ… è¦å‰‡è¡¨æ ¼ï¼šæå‰é¡¯ç¤º
        st.markdown("---")
        st.subheader("ğŸ§  æŸ¥è©¢çµæœåˆ†é¡è¦å‰‡")
        rules = [
            ["ğŸŸ¢ Scopus é¦–æ¬¡æ‰¾åˆ°", "Scopus", "æ¨™é¡Œå®Œå…¨ä¸€è‡´", "å¦"],
            ["ğŸŸ¢ Crossref å®Œå…¨åŒ…å«", "Crossref", "æŸ¥è©¢æ¨™é¡ŒåŒ…å«æ–¼ Crossref æ¨™é¡Œä¸­", "å¦"],
            ["ğŸŸ¡ Crossref é¡ä¼¼æ¨™é¡Œ", "Crossref", "æ¨™é¡Œç›¸ä¼¼åº¦ â‰¥ 0.9", "æ˜¯"],
            ["ğŸ”´ å‡æŸ¥ç„¡çµæœ", "â€”", "ç„¡ä»»ä½•çµæœæˆ–ç›¸ä¼¼åº¦éä½", "â€”"],
        ]
        df_rules = pd.DataFrame(rules, columns=["åˆ†é¡ç‡ˆè™Ÿ", "ä¾†æº", "æ¯”å°æ–¹å¼", "éœ€äººå·¥ç¢ºèª"])
        st.dataframe(df_rules, use_container_width=True)

        # âœ… çµæœå€é ç•™
        result_tabs_placeholder = st.empty()

        # âœ… é–‹å§‹æŸ¥è©¢
        st.subheader("ğŸ“Š æ­£åœ¨æŸ¥è©¢ä¸­ï¼Œè«‹ç¨å€™...")
        scopus_results = {}
        crossref_exact = {}
        crossref_similar = {}
        not_found = []

        progress_bar = st.progress(0.0)

        for i, title in enumerate(titles, 1):
            msg_box = st.empty()
            with st.status(f"ğŸ” ç¬¬ {i} ç­†ï¼š`{title}`", expanded=True) as status:
                msg_box.markdown("ğŸ“¡ æ­£åœ¨æŸ¥ Scopus...")
                url = search_scopus_by_title(title)
                if url:
                    scopus_results[title] = url
                    msg_box.markdown("âœ… å·²æ‰¾åˆ°æ–¼ **Scopus**")
                    status.update(label=f"ğŸŸ¢ ç¬¬ {i} ç­†æˆåŠŸï¼ˆScopusï¼‰", state="complete")
                else:
                    msg_box.markdown("ğŸ” Scopus ç„¡çµæœï¼Œæ”¹æŸ¥ Crossref...")
                    match_type, url = search_crossref_by_title(title)
                    if match_type == "exact":
                        crossref_exact[title] = url
                        msg_box.markdown("âœ… Crossref å®Œå…¨åŒ…å«")
                        status.update(label=f"ğŸŸ¢ ç¬¬ {i} ç­†æˆåŠŸï¼ˆCrossref å®Œå…¨åŒ…å«ï¼‰", state="complete")
                    elif match_type == "similar":
                        crossref_similar[title] = url
                        msg_box.markdown("ğŸŸ¡ Crossref æ¨™é¡Œç›¸ä¼¼ï¼ˆå»ºè­°äººå·¥ç¢ºèªï¼‰")
                        status.update(label=f"ğŸŸ¡ ç¬¬ {i} ç­†ç›¸ä¼¼ï¼ˆéœ€ç¢ºèªï¼‰", state="complete")
                    else:
                        not_found.append(title)
                        msg_box.markdown("âŒ Crossref ä¹Ÿç„¡çµæœ")
                        status.update(label=f"ğŸ”´ ç¬¬ {i} ç­†æœªæ‰¾åˆ°", state="error")
            progress_bar.progress(i / len(titles))

        # âœ… å°‡çµæœå¡«å…¥é ç•™å€å¡Š
        with result_tabs_placeholder.container():
            st.markdown("---")
            st.subheader("ğŸ“Š æŸ¥è©¢çµæœåˆ†é¡")

            tab1, tab2, tab3, tab4 = st.tabs([
                f"ğŸŸ¢ Scopus é¦–æ¬¡æ‰¾åˆ°ï¼ˆ{len(scopus_results)}ï¼‰",
                f"ğŸŸ¢ Crossref å®Œå…¨åŒ…å«ï¼ˆ{len(crossref_exact)}ï¼‰",
                f"ğŸŸ¡ Crossref é¡ä¼¼æ¨™é¡Œï¼ˆ{len(crossref_similar)}ï¼‰",
                f"ğŸ”´ å‡æŸ¥ç„¡çµæœï¼ˆ{len(not_found)}ï¼‰"
            ])

            with tab1:
                if scopus_results:
                    for i, (title, url) in enumerate(scopus_results.items(), 1):
                        with st.expander(f"{i}. {title}"):
                            st.markdown(f"ğŸ”— [Scopus é€£çµ]({url})", unsafe_allow_html=True)
                else:
                    st.info("Scopus ç„¡ä»»ä½•å‘½ä¸­çµæœã€‚")

            with tab2:
                if crossref_exact:
                    for i, (title, url) in enumerate(crossref_exact.items(), 1):
                        with st.expander(f"{i}. {title}"):
                            st.markdown(f"ğŸ”— [Crossref é€£çµ]({url})", unsafe_allow_html=True)
                else:
                    st.info("Crossref ç„¡å®Œå…¨åŒ…å«çµæœã€‚")

            with tab3:
                if crossref_similar:
                    for i, (title, url) in enumerate(crossref_similar.items(), 1):
                        with st.expander(f"{i}. {title}"):
                            st.markdown(f"ğŸ”— [ç›¸ä¼¼è«–æ–‡é€£çµ]({url})", unsafe_allow_html=True)
                            st.warning("âš ï¸ æ­¤ç‚ºç›¸ä¼¼æ¨™é¡Œï¼Œè«‹äººå·¥ç¢ºèªæ˜¯å¦ç‚ºæ­£ç¢ºæ–‡ç»ã€‚")
                else:
                    st.info("ç„¡æ¨™é¡Œç›¸ä¼¼ä½†ä¸ä¸€è‡´çš„çµæœã€‚")

            with tab4:
                if not_found:
                    for i, title in enumerate(not_found, 1):
                        st.markdown(f"{i}. {title}")
                    st.markdown("ğŸ‘‰ è«‹è€ƒæ…®æ‰‹å‹•æœå°‹ Google Scholarã€‚")
                else:
                    st.success("æ‰€æœ‰æ¨™é¡Œçš†æˆåŠŸæŸ¥è©¢ï¼")
